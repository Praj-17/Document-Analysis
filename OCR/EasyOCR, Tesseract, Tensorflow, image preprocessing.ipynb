{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing required modules\n",
    "import PyPDF2\n",
    "\t\n",
    "# creating a pdf file object\n",
    "pdfFileObj = open('injection5.pdf', 'rb')\n",
    "\t\n",
    "# creating a pdf reader object\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\t\n",
    "# printing number of pages in pdf file\n",
    "print(pdfReader.numPages)\n",
    "\t\n",
    "# creating a page object\n",
    "pageObj = pdfReader.getPage(0)\n",
    "\t\n",
    "# extracting text from page\n",
    "print(pageObj.extractText())\n",
    "\t\n",
    "# closing the pdf file object\n",
    "pdfFileObj.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "with pdfplumber.open('Injection5.pdf') as pdf:\n",
    "    first_page = pdf.pages[0]\n",
    "    print(first_page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EASYOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easyocr\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "IMAGE_PATH = 'p3-27.png'\n",
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(IMAGE_PATH,paragraph=\"False\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_PATH = '3860.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(IMAGE_PATH,paragraph=\"False\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_PATH = 'p7-65.png'\n",
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(IMAGE_PATH,paragraph=\"False\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tesseract\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import sys\n",
    "\n",
    "img_cv = cv2.imread(sys.path[0]+'/p3-27.png', 1)\n",
    "\n",
    "# By default OpenCV stores images in BGR format and since pytesseract assumes RGB format,\n",
    "# we need to convert from BGR to RGB format/mode:\n",
    "img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "print(pytesseract.image_to_string(img_rgb))\n",
    "# OR\n",
    "img_rgb = Image.frombytes('RGB', img_cv.shape[:2], img_cv, 'raw', 'BGR', 0, 0)\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "# If you don't have tesseract executable in your PATH, include the following:\n",
    "##pytesseract.pytesseract.tesseract_cmd = r'<full_path_to_your_tesseract_executable>'\n",
    "# Example tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "# Simple image to string\n",
    "print(pytesseract.image_to_string(Image.open('test.png')))\n",
    "\n",
    "# In order to bypass the image conversions of pytesseract, just use relative or absolute image path\n",
    "# NOTE: In this case you should provide tesseract supported images or tesseract will return error\n",
    "print(pytesseract.image_to_string('test.png'))\n",
    "\n",
    "# List of available languages\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "# French text image to string\n",
    "print(pytesseract.image_to_string(Image.open('test-european.jpg'), lang='fra'))\n",
    "\n",
    "# Batch processing with a single file containing the list of multiple image file paths\n",
    "print(pytesseract.image_to_string('images.txt'))\n",
    "\n",
    "# Timeout/terminate the tesseract job after a period of time\n",
    "try:\n",
    "    print(pytesseract.image_to_string('test.jpg', timeout=2)) # Timeout after 2 seconds\n",
    "    print(pytesseract.image_to_string('test.jpg', timeout=0.5)) # Timeout after half a second\n",
    "except RuntimeError as timeout_error:\n",
    "    # Tesseract processing is terminated\n",
    "    pass\n",
    "\n",
    "# Get bounding box estimates\n",
    "print(pytesseract.image_to_boxes(Image.open('test.png')))\n",
    "\n",
    "# Get verbose data including boxes, confidences, line and page numbers\n",
    "print(pytesseract.image_to_data(Image.open('test.png')))\n",
    "\n",
    "# Get information about orientation and script detection\n",
    "print(pytesseract.image_to_osd(Image.open('test.png')))\n",
    "\n",
    "# Get a searchable PDF\n",
    "pdf = pytesseract.image_to_pdf_or_hocr('test.png', extension='pdf')\n",
    "with open('test.pdf', 'w+b') as f:\n",
    "    f.write(pdf) # pdf type is bytes by default\n",
    "\n",
    "# Get HOCR output\n",
    "hocr = pytesseract.image_to_pdf_or_hocr('test.png', extension='hocr')\n",
    "\n",
    "# Get ALTO XML output\n",
    "xml = pytesseract.image_to_alto_xml('test.png')\n",
    "Support for OpenCV image/NumPy array objects\n",
    "\n",
    "import cv2\n",
    "\n",
    "img_cv = cv2.imread(r'/<path_to_image>/digits.png')\n",
    "\n",
    "# By default OpenCV stores images in BGR format and since pytesseract assumes RGB format,\n",
    "# we need to convert from BGR to RGB format/mode:\n",
    "img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "print(pytesseract.image_to_string(img_rgb))\n",
    "# OR\n",
    "img_rgb = Image.frombytes('RGB', img_cv.shape[:2], img_cv, 'raw', 'BGR', 0, 0)\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"Capture.JPG\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"3860.JPG\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"p2-13.png\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"p2-15.png\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"p3-25.png\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"p4-36.png\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"p5-47.png\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"p6-59.png\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"p7-65.png\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow EAST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "def east_detect(image):\n",
    "    layerNames = [\n",
    "    \t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "    \t\"feature_fusion/concat_3\"]\n",
    "    \n",
    "    orig = image.copy()\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height: Should be multiple of 32\n",
    "    (newW, newH) = (320, 320)\n",
    "    \n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "    \n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    \n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "    \t(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    \n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    \n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the geometrical\n",
    "        # data used to derive potential bounding box coordinates that\n",
    "        # surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "    \n",
    "        for x in range(0, numCols):\n",
    "    \t\t# if our score does not have sufficient probability, ignore it\n",
    "            # Set minimum confidence as required\n",
    "            if scoresData[x] < 0.5:\n",
    "                continue\n",
    "    \t\t# compute the offset factor as our resulting feature maps will\n",
    "            #  x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "            # extract the rotation angle for the prediction and then\n",
    "            # compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "            # compute both the starting and ending (x, y)-coordinates for\n",
    "            # the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "            # add the bounding box coordinates and probability score to\n",
    "            # our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "                        \n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "    \t# scale the bounding box coordinates based on the respective\n",
    "    \t# ratios\n",
    "    \tstartX = int(startX * rW)\n",
    "    \tstartY = int(startY * rH)\n",
    "    \tendX = int(endX * rW)\n",
    "    \tendY = int(endY * rH)\n",
    "    \t# draw the bounding box on the image\n",
    "    \tcv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "    print(time.time() - start)\n",
    "    return orig\n",
    "\n",
    "image = cv2.imread(\"3860.jpg\")\n",
    "\n",
    "out_image = east_detect(image)\n",
    "\n",
    "cv2.imwrite(\"sample_output.jpg\", out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image preprocessing and tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start recognize text from image ---\n",
      "Sharp Corner\n",
      "Raises Stress\n",
      "Concentration\n",
      "\n",
      "f—\n",
      "\n",
      "qt\n",
      "x Poor\n",
      "\n",
      "Corner Radius\n",
      "Minimizes Stress\n",
      "Concentration\n",
      "\n",
      "R,=1/2xT\n",
      "T\n",
      "\n",
      "R, = 3/2xT\n",
      "\n",
      "Good\n",
      "\n",
      "------ Done -------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "#tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract'\n",
    "# Path of working folder on Disk\n",
    "#imh_path = \"3860.jpg\"\n",
    "def get_string(img_path):\n",
    "    # Read image with opencv\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Convert to gray\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply dilation and erosion to remove some noise\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "    # Write image after removed noise\n",
    "    cv2.imwrite(\"removed_noise.png\", img)\n",
    "\n",
    "    #  Apply threshold to get image with only black and white\n",
    "    #img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "    # Write the image after apply opencv to do some ...\n",
    "    cv2.imwrite(img_path, img)\n",
    "\n",
    "    # Recognize text with tesseract for python\n",
    "    result = pytesseract.image_to_string(Image.open(img_path))\n",
    "\n",
    "    # Remove template file\n",
    "    #os.remove(temp)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "print ('--- Start recognize text from image ---')\n",
    "print (get_string(\"p5-47.png\"))\n",
    "\n",
    "print (\"------ Done -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ivanpp/detectron2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIB INTERSECTIONS\n",
      "\n",
      "Because the thickness of the material will be greater at\n",
      "the rib intersections, coring or another means of ma-\n",
      "terial removal should be employed to avoid excessive\n",
      "sinking from occurring on the opposite side.\n",
      "\n",
      "Core at Rib\n",
      "Intersection\n",
      "Minimizes Sink\n",
      "\n",
      "    \n",
      "\n",
      "Figure 10: Coring at rib intersections\n",
      "\n",
      "RIB GUILDELINES\n",
      "\n",
      "The height of a rib should be limited to less than three\n",
      "times its thickness. It is better to use multiple ribs to\n",
      "increase bending stiffness than to use one very tall rib.\n",
      "\n",
      "Tf | fF —\n",
      "ie iF\n",
      "\n",
      "S 2(2xT) —}—+|\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "W=\n",
      "40-60% of T\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Figure 11: Design guidelines for ribs\n",
      "\n",
      "RIB/LOAD AFFECT ON STIFFNESS\n",
      "\n",
      "A rib is oriented in such a way as to provide maximum\n",
      "bending stiffness to the part. By paying attention to part\n",
      "geometry, designers must be conscious of the orienta-\n",
      "tion of the rib to the bending load or there will be no\n",
      "increase in stiffness.\n",
      "\n",
      "    \n",
      "\n",
      "Reaction\n",
      "Force\n",
      "\n",
      "Rib\n",
      "\n",
      "A ie\n",
      "\n",
      "Reaction\n",
      "\n",
      "Force Reaction\n",
      "\n",
      "Reaction Force\n",
      "\n",
      "Force\n",
      "\n",
      "Figure 12: Rib/ load orientation affects part stiffness;\n",
      "Draft angles for ribs should be a minimum of 0.25 to 0.5\n",
      "degree of draft per side\n",
      "\n",
      "DRAFT AND TEXTURE\n",
      "\n",
      "Mold drafts facilitate part removal from the mold. The\n",
      "draft must be in an offset angle that is parallel to the\n",
      "mold opening and closing. The ideal draft angle for\n",
      "a given part depends on the depth of the part in the\n",
      "mold and its required end-use function.\n",
      "\n",
      " \n",
      "\n",
      "Figure 12: Draft Angle\n",
      "\n",
      "Allowing for as much draft as possible will permit parts\n",
      "to release from the mold easily. Typically, one to two\n",
      "degrees of drafts with an additional 1.5 degrees per\n",
      "0.25mm depth of texture is enough to do the trick.\n",
      "\n",
      "The mold part line will need to be located in a way that\n",
      "splits the draft in order to minimize it. If no draft is ac-\n",
      "ceptable due to design considerations, a side action\n",
      "mold may be required.\n",
      "\f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "file = Image.open(\"Injection.jpg\")\n",
    "str = pytesseract.image_to_string(file, lang='eng')\n",
    "\n",
    "print(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
